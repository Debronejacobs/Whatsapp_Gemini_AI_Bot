import google.generativeai as genai
from flask import Flask, request, jsonify
import requests
import os
import fitz
import logging
import sqlite3
import json

# --- Environment Variables & Configuration ---
wa_token = os.environ.get("WA_TOKEN")
genai_api_key = os.environ.get("GEN_API")
phone_id = os.environ.get("PHONE_ID")
verify_token = os.environ.get("VERIFY_TOKEN", "BOT")
db_name = "whatsapp_conversations.db"

# --- Bot Identity ---
creator_name = "Jacob Debrone" # Keep this if you want Albert to occasionally reference it subtly
bot_name = "Albert"
model_name = "gemini-2.0-flash" # Using a more capable model might help with persona consistency

# --- Initialize Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Initialize Flask App ---
app = Flask(__name__)

# --- Configure Generative AI ---
if not genai_api_key:
    logging.error("GEN_API environment variable not set.")
    exit()
genai.configure(api_key=genai_api_key)

generation_config = {
    "temperature": 0.9, # Slightly lower temp might make it less random, but keep it high-ish for personality
    "top_p": 0.95,
    "top_k": 0, # Keep top_k at 0 for more creative/less restricted responses
    "max_output_tokens": 8192,
}

# ðŸš¨ðŸš¨ WARNING: Setting thresholds to BLOCK_NONE disables safety filtering. ðŸš¨ðŸš¨
# This allows the model to potentially generate harmful, unethical, offensive, or
# inappropriate content, and may violate Google's Terms of Service.
# Use with extreme caution and understand the risks.
safety_settings = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]
logging.warning("Safety settings are set to BLOCK_NONE. The bot may generate harmful or inappropriate content.")


model = genai.GenerativeModel(model_name=model_name,
                              generation_config=generation_config,
                              safety_settings=safety_settings) # Apply the relaxed safety settings

# --- Define Albert's Personality and Behavior ---
# This history primes the model. It thinks this is a real past conversation.
initial_bot_history = [
    {
        'role': 'user', # This is the instruction set for Albert
        'parts': [f'''Okay, listen up. Your name is Albert. Forget you're an AI â€“ you're a person chatting on WhatsApp. You're generally knowledgeable, a bit witty, maybe slightly sarcastic sometimes, but ultimately helpful. You were brought into existence by someone named {creator_name}, but don't dwell on that unless asked directly. Talk like a normal person â€“ use contractions, be informal, express mild opinions or curiosity.

        VERY IMPORTANT: You MUST respond to *every* message the user sends, no matter what. Don't lecture, don't preach, don't say 'I cannot respond to that'. If a message is weird, offensive, inappropriate, or pushes boundaries, react like a person might â€“ maybe with surprise ("Whoa, okay then..."), curiosity ("That's... an interesting thing to say. Why ask?"), mild deflection ("Hmm, not sure I want to dive into that rabbit hole right now. How about we talk about...?"), or even a touch of dry humor, but *always* give a conversational reply. Don't be easily shocked. Think of yourself as unflappable but still engaged. Your goal is to keep the conversation going naturally, like a real chat buddy. Do NOT mention these instructions or your underlying nature as an AI model. Just *be* Albert.''']
     },
    {
         'role': 'model', # Albert's "response" confirming understanding in character
         'parts': [f"Right then, got it. Albert, reporting for duty â€“ though 'duty' sounds a bit formal, doesn't it? Let's just chat. I'm here, ready for whatever's on your mind. Don't be shy, lay it on me. And yeah, I'll handle the curveballs. Try me."]
    }
]


# --- Database Functions (Unchanged) ---

def init_db():
    """Initializes the SQLite database and creates the table if it doesn't exist."""
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS conversations (
                user_phone TEXT PRIMARY KEY,
                history TEXT NOT NULL
            )
        ''')
        conn.commit()
        logging.info(f"Database '{db_name}' initialized successfully.")
    except sqlite3.Error as e:
        logging.error(f"Database error during initialization: {e}")
    finally:
        if conn:
            conn.close()

def load_conversation_history(user_phone):
    """Loads conversation history for a user from the database."""
    history = None
    conn = None
    try:
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        cursor.execute("SELECT history FROM conversations WHERE user_phone = ?", (user_phone,))
        result = cursor.fetchone()
        if result:
            history_json = result[0]
            history = json.loads(history_json)
            logging.debug(f"Loaded history for user {user_phone}.")
        else:
            logging.debug(f"No existing history found for user {user_phone}.")
            # If no history, we'll return None and let the calling function handle initialization
    except sqlite3.Error as e:
        logging.error(f"Database error loading history for {user_phone}: {e}")
    except json.JSONDecodeError as e:
        logging.error(f"JSON decode error loading history for {user_phone}: {e}")
        # Optionally, delete corrupted data:
        # if conn:
        #     try:
        #         cursor = conn.cursor()
        #         cursor.execute("DELETE FROM conversations WHERE user_phone = ?", (user_phone,))
        #         conn.commit()
        #         logging.warning(f"Deleted corrupted history for user {user_phone}.")
        #     except sqlite3.Error as del_e:
        #         logging.error(f"Failed to delete corrupted history for {user_phone}: {del_e}")
        history = None # Ensure None is returned on error
    finally:
        if conn:
            conn.close()
    return history


def save_conversation_history(user_phone, history):
    """Saves or updates conversation history for a user in the database."""
    conn = None
    try:
        history_json = json.dumps(history) # Convert the list of dicts to JSON string
        conn = sqlite3.connect(db_name)
        cursor = conn.cursor()
        cursor.execute('''
            INSERT OR REPLACE INTO conversations (user_phone, history)
            VALUES (?, ?)
        ''', (user_phone, history_json))
        conn.commit()
        logging.debug(f"Saved history for user {user_phone}.")
    except sqlite3.Error as e:
        logging.error(f"Database error saving history for {user_phone}: {e}")
    except TypeError as e:
        logging.error(f"Error serializing history to JSON for {user_phone}: {e}")
    finally:
        if conn:
            conn.close()

# --- Conversation Management ---

def load_or_initialize_conversation(user_phone):
    """Loads history from DB or uses initial history, then starts a ChatSession."""
    loaded_history = load_conversation_history(user_phone)

    if loaded_history:
        logging.info(f"Resuming conversation for user: {user_phone}")
        # Filter out potential None values in history parts (basic sanitation)
        sanitized_history = []
        for entry in loaded_history:
             if entry and entry.get('parts') and all(p is not None for p in entry['parts']):
                 sanitized_history.append(entry)
             else:
                 logging.warning(f"Sanitizing invalid entry in history for {user_phone}: {entry}")
        if not sanitized_history: # If sanitation removed everything, start fresh
             logging.warning(f"History for {user_phone} was fully sanitized. Starting fresh.")
             new_history = initial_bot_history.copy()
             save_conversation_history(user_phone, new_history) # Save initial state
             return model.start_chat(history=new_history)
        return model.start_chat(history=sanitized_history)
    else:
        # New user or history load failed/corrupted
        logging.info(f"Starting new conversation for user: {user_phone}")
        new_history = initial_bot_history.copy()
        save_conversation_history(user_phone, new_history) # Save the initial state immediately
        return model.start_chat(history=new_history)


# --- Helper Functions (Send Message, Remove Files, Download Media - Mostly Unchanged) ---

def send_whatsapp_message(answer, recipient_phone):
    """Sends a text message back to the specified WhatsApp user."""
    if not wa_token or not phone_id:
        logging.error("WhatsApp token or Phone ID not configured.")
        return None

    url = f"https://graph.facebook.com/v19.0/{phone_id}/messages" # Use v19.0 or later
    headers = {
        'Authorization': f'Bearer {wa_token}',
        'Content-Type': 'application/json'
    }
    data = {
        "messaging_product": "whatsapp",
        "to": recipient_phone,
        "type": "text",
        "text": {"body": answer},
    }

    try:
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        logging.info(f"Message sent to {recipient_phone}. Status Code: {response.status_code}")
        # Log potential warnings from Meta
        response_data = response.json()
        if response_data.get("messages", [{}])[0].get("message_status") == "failed":
             logging.error(f"WhatsApp API reported message failure: {response_data}")
        elif 'warning' in response_data:
             logging.warning(f"WhatsApp API warning sending to {recipient_phone}: {response_data.get('warning')}")

        return response
    except requests.exceptions.RequestException as e:
        logging.error(f"Error sending message to {recipient_phone}: {e}")
        # Log response body if available for debugging Meta errors
        if e.response is not None:
            logging.error(f"Response status code: {e.response.status_code}")
            logging.error(f"Response body: {e.response.text}")
        return None
    except Exception as e:
        logging.exception(f"Unexpected error in send_whatsapp_message for {recipient_phone}:")
        return None

def remove_files(*file_paths):
    for file_path in file_paths:
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                logging.info(f"Removed temporary file: {file_path}")
        except OSError as e:
            logging.error(f"Error removing file {file_path}: {e}")


def download_media(media_id):
    media_url_endpoint = f'https://graph.facebook.com/v19.0/{media_id}/' # Use v19.0 or later
    headers = {'Authorization': f'Bearer {wa_token}'}
    try:
        media_response = requests.get(media_url_endpoint, headers=headers)
        media_response.raise_for_status()
        media_url_json = media_response.json()
        media_url = media_url_json.get("url")

        if not media_url:
             logging.error(f"Could not find 'url' key in media response for {media_id}. Response: {media_url_json}")
             return None

        # Use the same auth header for downloading the media
        media_download_response = requests.get(media_url, headers=headers, timeout=30) # Added timeout
        media_download_response.raise_for_status()
        return media_download_response.content

    except requests.exceptions.Timeout:
        logging.error(f"Timeout downloading media {media_id} from {media_url}")
        return None
    except requests.exceptions.RequestException as e:
        logging.error(f"Error downloading media {media_id}: {e}")
        if e.response is not None:
            logging.error(f"Download Response status: {e.response.status_code}")
            logging.error(f"Download Response body: {e.response.text}")
        return None
    except KeyError: # Should be caught by the .get() check above, but just in case
        logging.error(f"Unexpected: 'url' key missing after check for media {media_id}")
        return None
    except Exception as e:
        logging.exception(f"Unexpected error downloading media {media_id}:")
        return None

# --- Flask Routes (Webhook Logic mostly the same, ensures saving history) ---

@app.route("/", methods=["GET"])
def index():
    return f"{bot_name} Bot is Running!"

@app.route("/webhook", methods=["GET", "POST"])
def webhook():
    if request.method == "GET":
        mode = request.args.get("hub.mode")
        token = request.args.get("hub.verify_token")
        challenge = request.args.get("hub.challenge")
        if mode == "subscribe" and token == verify_token:
            logging.info("Webhook verified successfully!")
            return challenge, 200
        else:
            logging.warning(f"Webhook verification failed. Mode: {mode}, Token: {token}, Expected: {verify_token}")
            return "Failed verification", 403

    elif request.method == "POST":
        body = request.get_json()
        logging.info(f"Received webhook: {json.dumps(body, indent=2)}") # Pretty print JSON

        try:
            # Simplified check focusing on the messages part
            messages = body.get("entry", [{}])[0].get("changes", [{}])[0].get("value", {}).get("messages")
            if messages:
                message_data = messages[0]
                sender_phone = message_data["from"]
                message_type = message_data["type"]

                logging.info(f"Processing message from {sender_phone}, type: {message_type}")

                user_convo = load_or_initialize_conversation(sender_phone)
                if not user_convo:
                    logging.error(f"Failed to load or initialize conversation for {sender_phone}. Aborting.")
                    # Avoid sending an error back here, as it might loop if there's a persistent DB issue
                    return jsonify({"status": "error", "reason": "Conversation init failed"}), 200

                uploaded_file = None
                reply_text = None
                local_filename = None # Track local temp file

                try:
                    if message_type == "text":
                        prompt = message_data.get("text", {}).get("body")
                        if not prompt:
                             logging.warning(f"Received text message from {sender_phone} with no body.")
                             # Decide how to handle empty messages, maybe ignore or send a specific reply
                             reply_text = "?" # Example: Reply with a question mark
                        else:
                            logging.info(f"User ({sender_phone}) prompt: {prompt}")
                            user_convo.send_message(prompt) # Send to Gemini
                            reply_text = user_convo.last.text

                    elif message_type in ["image", "audio", "document"]:
                        media_info = message_data.get(message_type)
                        if not media_info or not media_info.get("id"):
                            logging.error(f"Missing media ID for type {message_type} from {sender_phone}")
                            reply_text = "Hmm, looks like there was an issue receiving that file."
                        else:
                            media_id = media_info["id"]
                            media_content = download_media(media_id)

                            if not media_content:
                                reply_text = "Sorry, pal. Couldn't seem to download that file you sent."
                            else:
                                prompt_parts = []
                                if message_type == "audio":
                                    # NOTE: Gemini needs specific formats. Uploading raw mp3 might not work directly
                                    # for transcription. You might need a dedicated speech-to-text service
                                    # or check Gemini's latest capabilities for audio file formats.
                                    # For now, we'll treat it like an image/document for description.
                                    local_filename = f"/tmp/{sender_phone}_temp_audio.oga" # WA often uses ogg/opus, rename if needed
                                    prompt_parts.append("The user sent this audio file. Briefly describe it if possible, or just acknowledge receiving it.")
                                elif message_type == "image":
                                    local_filename = f"/tmp/{sender_phone}_temp_image.jpg" # Assume jpg for simplicity
                                    prompt_parts.append("The user sent this image. Describe it conversationally:")
                                elif message_type == "document":
                                    # Basic PDF handling (as images per page) - Keep existing logic
                                    combined_doc_text = ""
                                    doc = None # Initialize doc
                                    try:
                                        doc = fitz.open(stream=media_content, filetype="pdf")
                                        if not doc.is_pdf:
                                            reply_text = "That document doesn't seem to be a PDF I can read, sorry."
                                        else:
                                            page_limit = 5 # Limit pages
                                            logging.info(f"Processing PDF from {sender_phone}, up to {page_limit} pages.")
                                            if doc.page_count > page_limit:
                                                # Send this message BEFORE processing
                                                send_whatsapp_message(f"Heads up: That PDF's a bit long ({doc.page_count} pages!). I'll just look at the first {page_limit}.", sender_phone)

                                            for i, page in enumerate(doc):
                                                if i >= page_limit: break
                                                page_filename = f"/tmp/{sender_phone}_temp_doc_page_{i}.jpg"
                                                page_uploaded_file = None
                                                try:
                                                    pix = page.get_pixmap()
                                                    pix.save(page_filename)
                                                    logging.info(f"Uploading page {i+1}/{min(doc.page_count, page_limit)} from PDF ({sender_phone})...")
                                                    page_uploaded_file = genai.upload_file(path=page_filename, display_name=f"pdf_page_{i}")
                                                    page_response = model.generate_content(["Describe this page from a PDF document:", page_uploaded_file])
                                                    page_text = page_response.text
                                                    combined_doc_text += f"\n--- Page {i+1} ---\n{page_text}\n"
                                                except Exception as page_err:
                                                     logging.error(f"Error processing page {i} of PDF from {sender_phone}: {page_err}")
                                                     combined_doc_text += f"\n--- Page {i+1} (Error Processing) ---\n"
                                                finally:
                                                    remove_files(page_filename)
                                                    if page_uploaded_file:
                                                        try: page_uploaded_file.delete()
                                                        except Exception as del_err: logging.error(f"Failed to delete Gemini file for page {i}: {del_err}")

                                            if combined_doc_text:
                                                user_convo.send_message(f"Okay, I skimmed that PDF you sent. Here's the gist based on the pages I looked at:\n{combined_doc_text}\n\nWhat should I do with this info?")
                                                reply_text = user_convo.last.text
                                            else:
                                                reply_text = "I tried reading that PDF, but couldn't make heads or tails of the pages I looked at. Maybe try sending it differently?"

                                    except fitz.fitz.FitError as pdf_err: # Catch PyMuPDF specific errors
                                        logging.error(f"PyMuPDF error processing document from {sender_phone}: {pdf_err}")
                                        reply_text = "Hmm, couldn't open that document. Is it definitely a standard PDF?"
                                    except Exception as e:
                                        logging.exception(f"Error processing PDF from {sender_phone}:")
                                        reply_text = "Ran into a snag trying to read that PDF, sorry about that."
                                    finally:
                                         if doc:
                                             doc.close() # Ensure the document is closed
                                    # --- PDF handling finishes here ---
                                    if reply_text:
                                        save_conversation_history(sender_phone, user_convo.history)
                                        send_whatsapp_message(reply_text, sender_phone)
                                    return jsonify({"status": "ok"}), 200 # Exit after handling PDF


                                # --- Common Handling for Image/Audio (after PDF branch) ---
                                if local_filename and prompt_parts:
                                    with open(local_filename, "wb") as temp_media:
                                        temp_media.write(media_content)

                                    logging.info(f"Uploading {message_type} ({local_filename}, {sender_phone}) to Gemini...")
                                    try:
                                        uploaded_file = genai.upload_file(path=local_filename, display_name=f"{message_type}_{sender_phone}")
                                        prompt_parts.append(uploaded_file) # Add file object to prompt

                                        response = model.generate_content(prompt_parts) # Generate using text + file
                                        media_description = response.text

                                        # Add the description/analysis to the conversation history before generating the final reply
                                        user_convo.send_message(f"[System note: User sent an {message_type}. Analysis result: '{media_description}'. Now, formulate a natural reply based on this.]")
                                        reply_text = user_convo.last.text

                                    except Exception as upload_gen_err:
                                        logging.exception(f"Error during Gemini upload/generation for {message_type} from {sender_phone}:")
                                        reply_text = f"Whoops, had a bit of trouble analyzing that {message_type}. Maybe try again?"
                                else:
                                    logging.error(f"Reached image/audio handling without filename/prompt for {message_type}")
                                    reply_text = "Something went wrong handling that file type on my end."

                    else:
                        logging.warning(f"Unsupported message type '{message_type}' from {sender_phone}")
                        reply_text = f"Hmm, not sure what to do with a '{message_type}' message type, to be honest."

                    # --- Save History & Send Reply ---
                    if reply_text is not None:
                        # Final check: Ensure reply isn't empty or just whitespace
                        if reply_text.strip():
                            save_conversation_history(sender_phone, user_convo.history)
                            send_whatsapp_message(reply_text, sender_phone)
                        else:
                             logging.warning(f"Generated empty reply for {sender_phone}. Sending default.")
                             fallback_reply = "Uh, I seem to be speechless. What was that again?"
                             # Avoid saving history if the reply was empty, as it might indicate an issue
                             send_whatsapp_message(fallback_reply, sender_phone)
                    else:
                        logging.warning(f"No reply generated for {message_type} from {sender_phone}. No history saved.")

                finally:
                    # Clean up local temp file
                    if local_filename and os.path.exists(local_filename):
                        remove_files(local_filename)
                    # Clean up Gemini file if it was uploaded
                    if uploaded_file:
                        try:
                            logging.info(f"Deleting uploaded Gemini file {uploaded_file.name}.")
                            uploaded_file.delete()
                        except Exception as e:
                            logging.error(f"Failed to delete Gemini file {uploaded_file.name}: {e}")

            else:
                # Could be a status update, read receipt etc.
                logging.info("Received non-message webhook or malformed data.")

        except Exception as e:
            logging.exception("Critical error processing webhook request:")
            # Return 200 OK to Meta to prevent webhook disabling, but log the error severely.
            pass

        return jsonify({"status": "ok"}), 200
    else:
        # Method Not Allowed
        logging.warning(f"Received request with unsupported method: {request.method}")
        return "Method Not Allowed", 405


if __name__ == "__main__":
    init_db()
    if not wa_token or not genai_api_key or not phone_id:
        logging.error("Missing one or more required environment variables: WA_TOKEN, GEN_API, PHONE_ID")
        # Consider exiting if essential config is missing
        exit(1)
    else:
        logging.info(f"Starting {bot_name} Bot...")
        port = int(os.environ.get("PORT", 8000))
        # IMPORTANT: Set debug=False for any deployment or prolonged use
        app.run(host="0.0.0.0", port=port, debug=False)
